{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjal299/cv-project/blob/main/AML_Initial_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install image-classifiers"
      ],
      "metadata": {
        "id": "gRRiXuberuln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Downloader\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resize = \"512\" #@param [\"1024\", \"512\", \"256\"]\n",
        "crop = \"256\" #@param [\"1024\", \"512\", \"256\"]\n",
        "\n",
        "data_link_dict = {\n",
        "    'S2Looking': {\n",
        "      '1024_512': \"1-0_vcODMYmyYIY_uhMcs97aAk2OJVduq&confirm=t\",\n",
        "      '1024_256': \"1-0mVd6BjKnG3LXhYkbyxdx0-dtRKY6KO&confirm=t\",\n",
        "      '512_512': \"1-6WOmE0LTJ4Z31EphmA0L8QY5NMMllsT&confirm=t\",\n",
        "      '512_256': \"1-7NSOmHTsDpkEtbgt_N4VSgipCo5kr3a&confirm=t\",\n",
        "      '256_256': \"1-8x5d5DrNsgJ5eAOYyKwi91g8knGeRjQ&confirm=t\",\n",
        "      '1024_1024': \"1GzrgMwJKguXSWSfFsBSC2qSr52fVEc7W&confirm=t\"\n",
        "    },\n",
        "    'LEVIRCD_Plus': {\n",
        "      '1024_512': \"1-22GjfF8mlLFNyoJaa6_GMJRfTCoGZyc&confirm=t\",\n",
        "      '1024_256': \"1-2r-zCCfQjLRtwwXMGPYAxEJcTS8Hp80&confirm=t\",\n",
        "      '512_512': \"1-43scZrxe3Q_PH2EnBRuc_6l9O9WjPs2&confirm=t\",\n",
        "      '512_256': \"1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\",\n",
        "      '256_256': \"1-69cdgqlcXunt5vrCR9jRvcMkpPNzYWr&confirm=t\",\n",
        "      '1024_1024': \"1nyPJZGGOL7o8A0m0rGw7wyu2BFIxC4SD&confirm=t\"\n",
        "    }\n",
        "}\n",
        "\n",
        "import os\n",
        "if os.path.exists(f'Data/{dataset}/{resize}_{crop}'):\n",
        "  print('This dataset already exists.')\n",
        "else:\n",
        "  gdown_link = data_link_dict[dataset][f'{resize}_{crop}']\n",
        "  !gdown \"{gdown_link}\"\n",
        "  print('Unzipping...',end='')\n",
        "  !unzip -q \"{resize}_{crop}.zip\"\n",
        "  print('Done.\\nDeleting zip...',end='')\n",
        "  !rm \"{resize}_{crop}.zip\"\n",
        "  print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "jdXkHvK6gGr7",
        "outputId": "1de0b1f5-c169-4d00-967e-2c14fef04e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7NSOmHTsDpkEtbgt_N4VSgipCo5kr3a&confirm=t\n",
            "To: /content/512_256.zip\n",
            "100% 792M/792M [00:04<00:00, 159MB/s]\n",
            "Unzipping...Done.\n",
            "Deleting zip...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import cv2"
      ],
      "metadata": {
        "id": "B9GQ_AA1i5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Characteristics\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resized_size = \"512\" #@param [1024, 512, 256]\n",
        "crop_size = \"256\" #@param [1024, 512, 256]\n",
        "resized_size = int(resized_size)\n",
        "crop_size = int(crop_size)\n",
        "if dataset == 'S2Looking':\n",
        "  pre_image = 'Image1'\n",
        "  post_image = 'Image2'\n",
        "elif dataset == 'LEVIRCD_Plus':\n",
        "  pre_image = 'A'\n",
        "  post_image = 'B'\n",
        "label_image = 'label'\n",
        "PATH = f\"/content/Data/{dataset}/{resized_size}_{crop_size}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "AFi5x75Ek8IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "\n",
        "def iou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou_value = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "def miou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  tn = tf.cast(tf.reduce_sum((1-y_pred)*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou1 = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  iou2 = (tn + 1e-14) / (tn + fp + fn + 1e-14)\n",
        "  iou_value = (iou1 + iou2) / 2\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "# Losses"
      ],
      "metadata": {
        "id": "JGxDUbzFp6IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from classification_models.tfkeras import Classifiers\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "O3mqAH-HyxjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "es_patience = 15\n",
        "rLR_patience = 5\n",
        "lr = 1e-2\n",
        "optimizer = Adam(learning_rate = lr)\n",
        "loss = 'categorical_crossentropy'\n",
        "BATCH_SIZE = 16\n",
        "metrics = [iou, 'accuracy']"
      ],
      "metadata": {
        "id": "3UI_uqydsmA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #1\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def normalize(image, label):\n",
        "  image = image / 255\n",
        "  label = label / 255\n",
        "  return image, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  image, label = load(image_file)\n",
        "  image, label = normalize(image, label)\n",
        "  return image, label\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset_length = len(train_dataset)\n",
        "# train_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "val_dataset = val_dataset.map(load_image)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "val_dataset_length = len(val_dataset)\n",
        "# val_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "# test_dataset_length = len(os.listdir(f'{PATH}/train/{pre_image}/'))\n",
        "\n",
        "print(f'train_dataset_length: {train_dataset_length}, val_dataset_length: {val_dataset_length}, test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "id": "7uCJTn1Ot3pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "def ef_model(input_shape = (256, 256, 6), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = encoder.output\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = encoder_output\n",
        "  for i,skip_output in enumerate(skip_outputs):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skip_output.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skip_output])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = encoder.inputs, outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "5AN_EYMubtCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "input_shape = (crop_size, crop_size, 6)\n",
        "backbone = 'resnet18'\n",
        "model = ef_model(input_shape, backbone)\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_ef.h5', monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "\n",
        "model.load_weights('model_ef.h5')\n",
        "model.evaluate(test_dataset)\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n27RJ_hKb0Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #2 and #3\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  # image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return imageA, imageB, label\n",
        "\n",
        "def normalize(imageA, imageB, label):\n",
        "  imageA = imageA / 255\n",
        "  imageB = imageB / 255\n",
        "  label = label / 255\n",
        "  return imageA, imageB, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  imageA, imageB, label = load(image_file)\n",
        "  imageA, imageB, label = normalize(imageA, imageB, label)\n",
        "  return (imageA, imageB), label\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset_length = len(train_dataset)\n",
        "# train_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "val_dataset = val_dataset.map(load_image)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "val_dataset_length = len(val_dataset)\n",
        "# val_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "# test_dataset_length = len(os.listdir(f'{PATH}/train/{pre_image}/'))\n",
        "\n",
        "print(f'train_dataset_length: {train_dataset_length}, val_dataset_length: {val_dataset_length}, test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qilX5p3ckcON",
        "outputId": "b6c94fe1-3600-4d99-ab95-03a5895dd374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_length: 64, val_dataset_length: 64, test_dataset_length: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2\n",
        "def siamconc_model(input_shape = (256, 256, 3), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = [encoder.output]\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "  skips_model = Model(inputs = encoder.inputs, outputs = encoder_output + skip_outputs)\n",
        "  inputA = Input((crop_size, crop_size, 3))\n",
        "  inputB = Input((crop_size, crop_size, 3))\n",
        "  skipsA = skips_model(inputA)\n",
        "  skipsB = skips_model(inputB)\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = concatenate([skipsA[0], skipsB[0]])\n",
        "  for i,(skipA, skipB) in enumerate(zip(skipsA[1:], skipsB[1:])):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skipA.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skipA, skipB])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = [inputA, inputB], outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "E8NuEsnstNYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #2\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "backbone = 'resnet18'\n",
        "model = siamconc_model(input_shape, backbone)\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_siamconc.h5', monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "\n",
        "model.load_weights('model_siamconc.h5')\n",
        "model.evaluate(test_dataset)\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sp1mlciDtKWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3\n",
        "def siamdiff_model(input_shape = (256, 256, 3), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = [encoder.output]\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "  skips_model = Model(inputs = encoder.inputs, outputs = encoder_output + skip_outputs)\n",
        "  inputA = Input((crop_size, crop_size, 3))\n",
        "  inputB = Input((crop_size, crop_size, 3))\n",
        "  skipsA = skips_model(inputA)\n",
        "  skipsB = skips_model(inputB)\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = concatenate([skipsA[0], skipsB[0]])\n",
        "  for i,(skipA, skipB) in enumerate(zip(skipsA[1:], skipsB[1:])):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skipA.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skipA - skipB])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = [inputA, inputB], outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "N8fGCXH3tkKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #3\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "backbone = 'resnet18'\n",
        "model = siamdiff_model(input_shape, backbone)\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_siamdiff.h5', monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "\n",
        "model.load_weights('model_siamdiff.h5')\n",
        "model.evaluate(test_dataset)\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yf_YGoszkQFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}